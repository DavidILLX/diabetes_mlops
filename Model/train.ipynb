{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8cd98bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pickle\n",
    "import logging\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import catboost as cb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "075cd570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version: 3.12.7 | packaged by Anaconda, Inc. | (main, Oct  4 2024, 13:17:27) [MSC v.1929 64 bit (AMD64)]\n",
      "Pandas Version: 2.2.2\n",
      "NumPy Version: 1.26.4\n",
      "CatBoost Version: 1.2.8\n"
     ]
    }
   ],
   "source": [
    "print(\"Python Version:\", sys.version)\n",
    "print(\"Pandas Version:\", pd.__version__)\n",
    "print(\"NumPy Version:\", np.__version__)\n",
    "print(\"CatBoost Version:\", cb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "222dd94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d1a5bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    data_path = '../Data/'\n",
    "    path = os.path.join(data_path, filename)\n",
    "    with open(path, 'rb') as f_in:\n",
    "        X, y  = pickle.load(f_in)\n",
    "\n",
    "    if X.empty or y.empty:\n",
    "        logging.error(f'{filename} data is empty')\n",
    "    else:\n",
    "        logging.info('Data Loaded succesfully')\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "26214306",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-05 19:51:43,119 - INFO - Data Loaded succesfully\n",
      "2025-07-05 19:51:43,125 - INFO - Data Loaded succesfully\n"
     ]
    }
   ],
   "source": [
    "train = 'train.pkl'\n",
    "test = 'test.pkl'\n",
    "\n",
    "X_train, y_train = load_data(train)\n",
    "X_test, y_test = load_data(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "859ed676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "70687    1\n",
       "70688    1\n",
       "70689    1\n",
       "70690    1\n",
       "70691    1\n",
       "Name: Diabetes_binary, Length: 70692, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e4073231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BMI</th>\n",
       "      <th>Age</th>\n",
       "      <th>Income</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>Education</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>Fruits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70687</th>\n",
       "      <td>37</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70688</th>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70689</th>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70690</th>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70691</th>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70692 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       BMI  Age  Income  PhysHlth  Education  GenHlth  MentHlth  HighBP  \\\n",
       "0       26    4       8        30          6        3         5       1   \n",
       "1       26   12       8         0          6        3         0       1   \n",
       "2       26   13       8        10          6        1         0       0   \n",
       "3       28   11       8         3          6        3         0       1   \n",
       "4       29    8       8         0          5        2         0       0   \n",
       "...    ...  ...     ...       ...        ...      ...       ...     ...   \n",
       "70687   37    6       1         0          4        4         0       0   \n",
       "70688   29   10       6         0          3        2         0       0   \n",
       "70689   25   13       4         0          6        5        15       1   \n",
       "70690   18   11       4         0          2        4         0       1   \n",
       "70691   25    9       2         0          6        2         0       1   \n",
       "\n",
       "       Fruits  \n",
       "0           0  \n",
       "1           1  \n",
       "2           1  \n",
       "3           1  \n",
       "4           1  \n",
       "...       ...  \n",
       "70687       0  \n",
       "70688       1  \n",
       "70689       1  \n",
       "70690       0  \n",
       "70691       1  \n",
       "\n",
       "[70692 rows x 9 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e9749f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri('http://127.0.0.1:5000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a95be6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 'optimization_v3' (ID: 3) byl archivován.\n"
     ]
    }
   ],
   "source": [
    "old_experiment_name = \"optimization_v3\"\n",
    "\n",
    "try:\n",
    "    old_experiment = mlflow.get_experiment_by_name(old_experiment_name)\n",
    "\n",
    "    if old_experiment:\n",
    "        mlflow.delete_experiment(old_experiment.experiment_id)\n",
    "        print(f\"Experiment '{old_experiment_name}' (ID: {old_experiment.experiment_id}) byl archivován.\")\n",
    "    else:\n",
    "        print(f\"Experiment '{old_experiment_name}' nebyl nalezen.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Došlo k chybě při archivaci experimentu: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6403e59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/05 17:10:12 INFO mlflow.tracking.fluent: Experiment with name 'optimization_v4' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/4', creation_time=1751728213237, experiment_id='4', last_update_time=1751728213237, lifecycle_stage='active', name='optimization_v4', tags={}>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"optimization_v4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c4223b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-05 19:18:23,213 - INFO - build_posterior_wrapper took 0.002023 seconds\n",
      "2025-07-05 19:18:23,213 - INFO - TPE using 0 trials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support \n",
      "\n",
      "           0       0.94      0.73      0.82    213703\n",
      "           1       0.34      0.73      0.47     39977\n",
      "\n",
      "    accuracy                           0.73    253680\n",
      "   macro avg       0.64      0.73      0.64    253680\n",
      "weighted avg       0.84      0.73      0.77    253680\n",
      "\n",
      "🏃 View run receptive-midge-382 at: http://127.0.0.1:5000/#/experiments/4/runs/05906370bcaa42f9bf8ef379b701d006\n",
      "\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/4\n",
      "\n",
      "  2%|▏         | 1/50 [03:57<3:14:10, 237.76s/trial, best loss: 0.35561554099653914]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-05 19:22:20,972 - INFO - build_posterior_wrapper took 0.001504 seconds\n",
      "2025-07-05 19:22:20,972 - INFO - TPE using 1/1 trials with best loss 0.355616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run inquisitive-vole-962 at: http://127.0.0.1:5000/#/experiments/4/runs/77233f4a493e41f68f1ea30c0cb76104\n",
      "\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/4                        \n",
      "\n",
      "  2%|▏         | 1/50 [05:25<4:26:11, 325.95s/trial, best loss: 0.35561554099653914]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 53\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m: loss, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m: STATUS_OK}\n\u001b[0;32m     40\u001b[0m catboost_search_space \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdepth\u001b[39m\u001b[38;5;124m'\u001b[39m: scope\u001b[38;5;241m.\u001b[39mint(hp\u001b[38;5;241m.\u001b[39mquniform(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdepth\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m1\u001b[39m)),\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: hp\u001b[38;5;241m.\u001b[39mloguniform(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1.6\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom_seed\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m42\u001b[39m\n\u001b[0;32m     51\u001b[0m }\n\u001b[1;32m---> 53\u001b[0m best_result \u001b[38;5;241m=\u001b[39m fmin(\n\u001b[0;32m     54\u001b[0m     fn\u001b[38;5;241m=\u001b[39mcatboost_objective,\n\u001b[0;32m     55\u001b[0m     space\u001b[38;5;241m=\u001b[39mcatboost_search_space,\n\u001b[0;32m     56\u001b[0m     algo\u001b[38;5;241m=\u001b[39mtpe\u001b[38;5;241m.\u001b[39msuggest,\n\u001b[0;32m     57\u001b[0m     max_evals\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[0;32m     58\u001b[0m     trials\u001b[38;5;241m=\u001b[39mTrials()\n\u001b[0;32m     59\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\tomas\\anaconda3\\Lib\\site-packages\\hyperopt\\fmin.py:540\u001b[0m, in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    537\u001b[0m     fn \u001b[38;5;241m=\u001b[39m __objective_fmin_wrapper(fn)\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_trials_fmin \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(trials, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfmin\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 540\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trials\u001b[38;5;241m.\u001b[39mfmin(\n\u001b[0;32m    541\u001b[0m         fn,\n\u001b[0;32m    542\u001b[0m         space,\n\u001b[0;32m    543\u001b[0m         algo\u001b[38;5;241m=\u001b[39malgo,\n\u001b[0;32m    544\u001b[0m         max_evals\u001b[38;5;241m=\u001b[39mmax_evals,\n\u001b[0;32m    545\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    546\u001b[0m         loss_threshold\u001b[38;5;241m=\u001b[39mloss_threshold,\n\u001b[0;32m    547\u001b[0m         max_queue_len\u001b[38;5;241m=\u001b[39mmax_queue_len,\n\u001b[0;32m    548\u001b[0m         rstate\u001b[38;5;241m=\u001b[39mrstate,\n\u001b[0;32m    549\u001b[0m         pass_expr_memo_ctrl\u001b[38;5;241m=\u001b[39mpass_expr_memo_ctrl,\n\u001b[0;32m    550\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    551\u001b[0m         catch_eval_exceptions\u001b[38;5;241m=\u001b[39mcatch_eval_exceptions,\n\u001b[0;32m    552\u001b[0m         return_argmin\u001b[38;5;241m=\u001b[39mreturn_argmin,\n\u001b[0;32m    553\u001b[0m         show_progressbar\u001b[38;5;241m=\u001b[39mshow_progressbar,\n\u001b[0;32m    554\u001b[0m         early_stop_fn\u001b[38;5;241m=\u001b[39mearly_stop_fn,\n\u001b[0;32m    555\u001b[0m         trials_save_file\u001b[38;5;241m=\u001b[39mtrials_save_file,\n\u001b[0;32m    556\u001b[0m     )\n\u001b[0;32m    558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    559\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(trials_save_file):\n",
      "File \u001b[1;32mc:\\Users\\tomas\\anaconda3\\Lib\\site-packages\\hyperopt\\base.py:671\u001b[0m, in \u001b[0;36mTrials.fmin\u001b[1;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;66;03m# -- Stop-gap implementation!\u001b[39;00m\n\u001b[0;32m    667\u001b[0m \u001b[38;5;66;03m#    fmin should have been a Trials method in the first place\u001b[39;00m\n\u001b[0;32m    668\u001b[0m \u001b[38;5;66;03m#    but for now it's still sitting in another file.\u001b[39;00m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfmin\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fmin\n\u001b[1;32m--> 671\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fmin(\n\u001b[0;32m    672\u001b[0m     fn,\n\u001b[0;32m    673\u001b[0m     space,\n\u001b[0;32m    674\u001b[0m     algo\u001b[38;5;241m=\u001b[39malgo,\n\u001b[0;32m    675\u001b[0m     max_evals\u001b[38;5;241m=\u001b[39mmax_evals,\n\u001b[0;32m    676\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    677\u001b[0m     loss_threshold\u001b[38;5;241m=\u001b[39mloss_threshold,\n\u001b[0;32m    678\u001b[0m     trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    679\u001b[0m     rstate\u001b[38;5;241m=\u001b[39mrstate,\n\u001b[0;32m    680\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    681\u001b[0m     max_queue_len\u001b[38;5;241m=\u001b[39mmax_queue_len,\n\u001b[0;32m    682\u001b[0m     allow_trials_fmin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,  \u001b[38;5;66;03m# -- prevent recursion\u001b[39;00m\n\u001b[0;32m    683\u001b[0m     pass_expr_memo_ctrl\u001b[38;5;241m=\u001b[39mpass_expr_memo_ctrl,\n\u001b[0;32m    684\u001b[0m     catch_eval_exceptions\u001b[38;5;241m=\u001b[39mcatch_eval_exceptions,\n\u001b[0;32m    685\u001b[0m     return_argmin\u001b[38;5;241m=\u001b[39mreturn_argmin,\n\u001b[0;32m    686\u001b[0m     show_progressbar\u001b[38;5;241m=\u001b[39mshow_progressbar,\n\u001b[0;32m    687\u001b[0m     early_stop_fn\u001b[38;5;241m=\u001b[39mearly_stop_fn,\n\u001b[0;32m    688\u001b[0m     trials_save_file\u001b[38;5;241m=\u001b[39mtrials_save_file,\n\u001b[0;32m    689\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\tomas\\anaconda3\\Lib\\site-packages\\hyperopt\\fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    583\u001b[0m rval\u001b[38;5;241m.\u001b[39mcatch_eval_exceptions \u001b[38;5;241m=\u001b[39m catch_eval_exceptions\n\u001b[0;32m    585\u001b[0m \u001b[38;5;66;03m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[1;32m--> 586\u001b[0m rval\u001b[38;5;241m.\u001b[39mexhaust()\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_argmin:\n\u001b[0;32m    589\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(trials\u001b[38;5;241m.\u001b[39mtrials) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\tomas\\anaconda3\\Lib\\site-packages\\hyperopt\\fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexhaust\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    363\u001b[0m     n_done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials)\n\u001b[1;32m--> 364\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_evals \u001b[38;5;241m-\u001b[39m n_done, block_until_done\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masynchronous)\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\tomas\\anaconda3\\Lib\\site-packages\\hyperopt\\fmin.py:300\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    297\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoll_interval_secs)\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;66;03m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[1;32m--> 300\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mserial_evaluate()\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials_save_file \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\tomas\\anaconda3\\Lib\\site-packages\\hyperopt\\fmin.py:178\u001b[0m, in \u001b[0;36mFMinIter.serial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    176\u001b[0m ctrl \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mCtrl(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials, current_trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 178\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdomain\u001b[38;5;241m.\u001b[39mevaluate(spec, ctrl)\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    180\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjob exception: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(e))\n",
      "File \u001b[1;32mc:\\Users\\tomas\\anaconda3\\Lib\\site-packages\\hyperopt\\base.py:892\u001b[0m, in \u001b[0;36mDomain.evaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    884\u001b[0m     \u001b[38;5;66;03m# -- the \"work\" of evaluating `config` can be written\u001b[39;00m\n\u001b[0;32m    885\u001b[0m     \u001b[38;5;66;03m#    either into the pyll part (self.expr)\u001b[39;00m\n\u001b[0;32m    886\u001b[0m     \u001b[38;5;66;03m#    or the normal Python part (self.fn)\u001b[39;00m\n\u001b[0;32m    887\u001b[0m     pyll_rval \u001b[38;5;241m=\u001b[39m pyll\u001b[38;5;241m.\u001b[39mrec_eval(\n\u001b[0;32m    888\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpr,\n\u001b[0;32m    889\u001b[0m         memo\u001b[38;5;241m=\u001b[39mmemo,\n\u001b[0;32m    890\u001b[0m         print_node_on_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrec_eval_print_node_on_error,\n\u001b[0;32m    891\u001b[0m     )\n\u001b[1;32m--> 892\u001b[0m     rval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn(pyll_rval)\n\u001b[0;32m    894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rval, (\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39mnumber)):\n\u001b[0;32m    895\u001b[0m     dict_rval \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(rval), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m: STATUS_OK}\n",
      "Cell \u001b[1;32mIn[26], line 21\u001b[0m, in \u001b[0;36mcatboost_objective\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m     18\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Logging important metrics\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m cv_scores \u001b[38;5;241m=\u001b[39m cross_val_score(model, X_train, y_train, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_macro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     22\u001b[0m cv_score \u001b[38;5;241m=\u001b[39m cv_scores\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m     23\u001b[0m cv_std \u001b[38;5;241m=\u001b[39m cv_scores\u001b[38;5;241m.\u001b[39mstd()\n",
      "File \u001b[1;32mc:\\Users\\tomas\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\tomas\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:712\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    710\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 712\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m cross_validate(\n\u001b[0;32m    713\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m    714\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m    715\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m    716\u001b[0m     groups\u001b[38;5;241m=\u001b[39mgroups,\n\u001b[0;32m    717\u001b[0m     scoring\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m: scorer},\n\u001b[0;32m    718\u001b[0m     cv\u001b[38;5;241m=\u001b[39mcv,\n\u001b[0;32m    719\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[0;32m    720\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    721\u001b[0m     fit_params\u001b[38;5;241m=\u001b[39mfit_params,\n\u001b[0;32m    722\u001b[0m     params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m    723\u001b[0m     pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch,\n\u001b[0;32m    724\u001b[0m     error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[0;32m    725\u001b[0m )\n\u001b[0;32m    726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\tomas\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\tomas\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:423\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    422\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 423\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    424\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    425\u001b[0m         clone(estimator),\n\u001b[0;32m    426\u001b[0m         X,\n\u001b[0;32m    427\u001b[0m         y,\n\u001b[0;32m    428\u001b[0m         scorer\u001b[38;5;241m=\u001b[39mscorers,\n\u001b[0;32m    429\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    430\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    431\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    432\u001b[0m         parameters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    433\u001b[0m         fit_params\u001b[38;5;241m=\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mfit,\n\u001b[0;32m    434\u001b[0m         score_params\u001b[38;5;241m=\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mscorer\u001b[38;5;241m.\u001b[39mscore,\n\u001b[0;32m    435\u001b[0m         return_train_score\u001b[38;5;241m=\u001b[39mreturn_train_score,\n\u001b[0;32m    436\u001b[0m         return_times\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    437\u001b[0m         return_estimator\u001b[38;5;241m=\u001b[39mreturn_estimator,\n\u001b[0;32m    438\u001b[0m         error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[0;32m    439\u001b[0m     )\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[0;32m    441\u001b[0m )\n\u001b[0;32m    443\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    445\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tomas\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\tomas\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\tomas\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\tomas\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\tomas\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:888\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    886\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    887\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 888\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    890\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    891\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    892\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\tomas\\anaconda3\\Lib\\site-packages\\catboost\\core.py:5245\u001b[0m, in \u001b[0;36mCatBoostClassifier.fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, graph, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   5242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[0;32m   5243\u001b[0m     CatBoostClassifier\u001b[38;5;241m.\u001b[39m_check_is_compatible_loss(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m-> 5245\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X, y, cat_features, text_features, embedding_features, \u001b[38;5;28;01mNone\u001b[39;00m, graph, sample_weight, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, baseline, use_best_model,\n\u001b[0;32m   5246\u001b[0m           eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period,\n\u001b[0;32m   5247\u001b[0m           silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n\u001b[0;32m   5248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\tomas\\anaconda3\\Lib\\site-packages\\catboost\\core.py:2410\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, graph, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   2407\u001b[0m allow_clear_pool \u001b[38;5;241m=\u001b[39m train_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_clear_pool\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   2409\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m plot_wrapper(plot, plot_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining plots\u001b[39m\u001b[38;5;124m'\u001b[39m, [_get_train_dir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_params())]):\n\u001b[1;32m-> 2410\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train(\n\u001b[0;32m   2411\u001b[0m         train_pool,\n\u001b[0;32m   2412\u001b[0m         train_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval_sets\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   2413\u001b[0m         params,\n\u001b[0;32m   2414\u001b[0m         allow_clear_pool,\n\u001b[0;32m   2415\u001b[0m         train_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_model\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   2416\u001b[0m     )\n\u001b[0;32m   2418\u001b[0m \u001b[38;5;66;03m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[0;32m   2419\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_object\u001b[38;5;241m.\u001b[39m_get_loss_function_name()\n",
      "File \u001b[1;32mc:\\Users\\tomas\\anaconda3\\Lib\\site-packages\\catboost\\core.py:1790\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[1;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[0;32m   1789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_train\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[1;32m-> 1790\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_object\u001b[38;5;241m.\u001b[39m_train(train_pool, test_pool, params, allow_clear_pool, init_model\u001b[38;5;241m.\u001b[39m_object \u001b[38;5;28;01mif\u001b[39;00m init_model \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   1791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_trained_model_attributes()\n",
      "File \u001b[1;32m_catboost.pyx:5023\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_catboost.pyx:5072\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def catboost_objective(params):\n",
    "    with mlflow.start_run():\n",
    "        mlflow.set_tag('Model', 'Catboost')\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        categorical_features_indices = [X_train.columns.get_loc(col) for col in ['Age', 'GenHlth', 'Education', 'Income']]\n",
    "\n",
    "        model = CatBoostClassifier(**params,\n",
    "                                   cat_features=categorical_features_indices,\n",
    "                                   early_stopping_rounds=50,\n",
    "                                   eval_metric='TotalF1')\n",
    "\n",
    "        model.fit(X_train, y_train, \n",
    "                  eval_set=(X_test, y_test),\n",
    "                  use_best_model=True, \n",
    "                  logging_level='Silent')\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Logging important metrics\n",
    "        cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='f1_macro')\n",
    "        cv_score = cv_scores.mean()\n",
    "        cv_std = cv_scores.std()\n",
    "        mlflow.log_metric(\"cv_f1_mean\", cv_score)\n",
    "        mlflow.log_metric(\"cv_f1_std\", cv_std)\n",
    "        \n",
    "        score = f1_score(y_test, y_pred, average='macro')\n",
    "        loss = 1 - score \n",
    "        mlflow.log_metric('f1_macro', score)\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        mlflow.log_metric('accuracy', accuracy)\n",
    "\n",
    "        recall = recall_score(y_test, y_pred, average='macro')\n",
    "        mlflow.log_metric('recall', recall)\n",
    "\n",
    "    return {'loss': loss, 'status': STATUS_OK}\n",
    "\n",
    "catboost_search_space = {\n",
    "    'depth': scope.int(hp.quniform('depth', 4, 10, 1)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', -3, -1.6),\n",
    "    'l2_leaf_reg': hp.loguniform('l2_leaf_reg', -2, 1),\n",
    "    'bagging_temperature': hp.uniform('bagging_temperature', 0.0, 1.0),\n",
    "    'random_strength': hp.uniform('random_strength', 0.0, 1.0),\n",
    "    'border_count': scope.int(hp.quniform('border_count', 32, 64, 16)),\n",
    "    'iterations': 500,\n",
    "    'loss_function': 'Logloss',\n",
    "    'verbose': 0,\n",
    "    'random_seed': 42\n",
    "}\n",
    "\n",
    "best_result = fmin(\n",
    "    fn=catboost_objective,\n",
    "    space=catboost_search_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=50,\n",
    "    trials=Trials()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a71dba64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BMI          int64\n",
      "Age          int64\n",
      "Income       int64\n",
      "PhysHlth     int64\n",
      "Education    int64\n",
      "GenHlth      int64\n",
      "MentHlth     int64\n",
      "HighBP       int64\n",
      "Fruits       int64\n",
      "dtype: object\n",
      "   Age  GenHlth  Education  Income\n",
      "0    4        3          6       8\n",
      "1   12        3          6       8\n",
      "2   13        1          6       8\n",
      "3   11        3          6       8\n",
      "4    8        2          5       8\n",
      "Unique values in Age: [ 4 12 13 11  8  1  6  3  7 10  9  5  2]\n",
      "Unique values in GenHlth: [3 1 2 4 5]\n",
      "Unique values in Education: [6 5 4 3 2 1]\n",
      "Unique values in Income: [8 7 6 3 4 1 5 2]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.dtypes)\n",
    "print(X_train[['Age', 'GenHlth', 'Education', 'Income']].head())\n",
    "for col in ['Age', 'GenHlth', 'Education', 'Income']:\n",
    "    print(f\"Unique values in {col}: {X_train[col].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8471d69d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cac4e5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BMI          int64\n",
      "Age          int64\n",
      "Income       int64\n",
      "PhysHlth     int64\n",
      "Education    int64\n",
      "GenHlth      int64\n",
      "MentHlth     int64\n",
      "HighBP       int64\n",
      "Fruits       int64\n",
      "dtype: object\n",
      "   BMI  Age  Income  PhysHlth  Education  GenHlth  MentHlth  HighBP  Fruits\n",
      "0   26    4       8        30          6        3         5       1       0\n",
      "1   26   12       8         0          6        3         0       1       1\n",
      "2   26   13       8        10          6        1         0       0       1\n",
      "3   28   11       8         3          6        3         0       1       1\n",
      "4   29    8       8         0          5        2         0       0       1\n",
      "5   18    1       7         0          4        2         7       0       1\n",
      "6   26   13       6         0          5        1         0       0       1\n",
      "7   31    6       3         0          4        4         0       0       1\n",
      "8   32    3       8         0          6        3         0       0       1\n",
      "9   27    6       4         6          4        3         0       0       1\n",
      "[ 4 12 13 11  8  1  6  3  7 10  9  5  2]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.dtypes)\n",
    "print(X_train.head(10))\n",
    "print(X_train.iloc[:, 1].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45a6f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = xgb.DMatrix(X_train, label=y_train)\n",
    "valid = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "def xgboost_objective(params):\n",
    "    with mlflow.start_run():\n",
    "        mlflow.set_tag('Model', 'XGboost')\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        booster = xgb.train(\n",
    "            params=params,\n",
    "            dtrain=train,\n",
    "            num_boost_round=1000,\n",
    "            evals=[(valid, 'validation')],\n",
    "            early_stopping_rounds=50,\n",
    "            verbose_eval=False\n",
    "        )\n",
    "\n",
    "        y_pred_proba = booster.predict(valid) \n",
    "        y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "        \n",
    "        #Loggin important metrics\n",
    "        cv_scores = cross_val_score(booster, X_train, y_train, cv=5, scoring='f1_macro')\n",
    "        cv_score = cv_scores.mean()\n",
    "        cv_std = cv_scores.std()\n",
    "        mlflow.log_metric(\"cv_f1_mean\", cv_score)\n",
    "        mlflow.log_metric(\"cv_f1_std\", cv_std)\n",
    "\n",
    "        score = f1_score(y_test, y_pred, average='macro')\n",
    "        loss = 1 - score\n",
    "        mlflow.log_metric('f1_macro', score)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        mlflow.log_metric('accuracy', accuracy)\n",
    "\n",
    "        recall = recall_score(y_test, y_pred, average='macro')\n",
    "        mlflow.log_metric('recall', recall)\n",
    "\n",
    "    return {'loss': loss, 'status': STATUS_OK}\n",
    "\n",
    "search_space = {\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 3, 10, 1)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', -5, -1.6),\n",
    "    'reg_alpha': hp.loguniform('reg_alpha', -8, 0),\n",
    "    'reg_lambda': hp.loguniform('reg_lambda', -7, 0),\n",
    "    'min_child_weight': hp.loguniform('min_child_weight',  1, 10),\n",
    "    'subsample': hp.uniform('subsample', 0.6, 1.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.6, 1.0),\n",
    "    'objective': 'binary:logistic',\n",
    "    'num_class': 2,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "best_result = fmin(\n",
    "    fn=xgboost_objective,\n",
    "    space=search_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=50,\n",
    "    trials=Trials()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec81ca0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_objective(params):\n",
    "    with mlflow.start_run():\n",
    "        mlflow.set_tag('Model', 'Random Forest')\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        # Dependency bootstrap and oob_score\n",
    "        if not params['bootstrap']:\n",
    "            params['oob_score'] = False\n",
    "\n",
    "        model = RandomForestClassifier(\n",
    "            n_estimators=int(params['n_estimators']),\n",
    "            max_depth=params['max_depth'],\n",
    "            criterion=params['criterion'],\n",
    "            min_samples_split=int(params['min_samples_split']),\n",
    "            min_samples_leaf=int(params['min_samples_leaf']),\n",
    "            min_weight_fraction_leaf=params['min_weight_fraction_leaf'],\n",
    "            max_features=params['max_features'],\n",
    "            max_leaf_nodes=params['max_leaf_nodes'],\n",
    "            bootstrap=params['bootstrap'],\n",
    "            oob_score=params['oob_score'],\n",
    "            class_weight=params['class_weight'],\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "            )\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        #Logging important metrics\n",
    "        cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='f1_macro')\n",
    "        cv_score = cv_scores.mean()\n",
    "        cv_std = cv_scores.std()\n",
    "        mlflow.log_metric(\"cv_f1_mean\", cv_score)\n",
    "        mlflow.log_metric(\"cv_f1_std\", cv_std)\n",
    "        \n",
    "        f1 = f1_score(y_test, y_pred, average='macro')\n",
    "        loss = 1 - f1\n",
    "        mlflow.log_metric('f1_macro', f1)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        mlflow.log_metric('accuracy', accuracy)\n",
    "\n",
    "        recall = recall_score(y_test, y_pred, average='macro')\n",
    "        mlflow.log_metric('recall', recall)\n",
    "\n",
    "        return {'loss': loss, 'status': STATUS_OK}\n",
    "    \n",
    "\n",
    "search_space = {\n",
    "    'n_estimators': scope.int(hp.quniform('n_estimators', 100, 1000, 100)),\n",
    "    'max_depth': hp.choice('max_depth', [None] + [scope.int(hp.quniform('max_depth_val', 5, 50, 1))]),\n",
    "    'criterion': hp.choice('criterion', ['gini', 'entropy', 'log_loss']),\n",
    "    'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 20, 1)),\n",
    "    'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 20, 1)),\n",
    "    'min_weight_fraction_leaf': hp.uniform('min_weight_fraction_leaf', 0.0, 0.4),\n",
    "    'max_features': hp.choice('max_features', ['sqrt', 'log2', None]),\n",
    "    'max_leaf_nodes': hp.choice('max_leaf_nodes', [None] + [scope.int(hp.quniform('max_leaf_nodes_val', 10, 100, 1))]),\n",
    "    'bootstrap': hp.choice('bootstrap', [True, False]),\n",
    "    'oob_score': hp.choice('oob_score', [True, False]),\n",
    "    'class_weight': hp.choice('class_weight', ['balanced', None])\n",
    "    }\n",
    "\n",
    "best_result = fmin(\n",
    "    fn=rf_objective,\n",
    "    space=search_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=50,\n",
    "    trials=Trials()\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261f4166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg_objective(params):\n",
    "    with mlflow.start_run():\n",
    "        mlflow.set_tag('Model', 'LogisticRegression')\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        model = LogisticRegression(\n",
    "            penalty=params['penalty'],\n",
    "            C=params['C'],\n",
    "            solver=params['solver'],\n",
    "            class_weight='balanced',\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        #Loggin important metrics\n",
    "        cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='f1_macro')\n",
    "        cv_score = cv_scores.mean()\n",
    "        cv_std = cv_scores.std()\n",
    "        mlflow.log_metric(\"cv_f1_mean\", cv_score)\n",
    "        mlflow.log_metric(\"cv_f1_std\", cv_std)\n",
    "\n",
    "        score = f1_score(y_test, y_pred, average='macro')\n",
    "        loss = 1 - score\n",
    "        mlflow.log_metric('f1_macro', score)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        mlflow.log_metric('accuracy', accuracy)\n",
    "\n",
    "        recall = recall_score(y_test, y_pred, average='macro')\n",
    "        mlflow.log_metric('recall', recall)\n",
    "\n",
    "    return {'loss': loss, 'status': STATUS_OK}\n",
    "\n",
    "logreg_search_space = {\n",
    "    'penalty': hp.choice('penalty', ['l1', 'l2']),\n",
    "    'C': hp.loguniform('C', -4, 2),\n",
    "    'solver': hp.choice('solver', ['liblinear', 'saga'])\n",
    "}\n",
    "\n",
    "best_result = fmin(\n",
    "    fn=logreg_objective,\n",
    "    space=logreg_search_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=50,\n",
    "    trials=Trials()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
